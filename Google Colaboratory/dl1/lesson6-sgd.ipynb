{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lesson6-sgd.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0ywy-t5AdxWr","colab_type":"text"},"cell_type":"markdown","source":["# Table of Contents\n"," <p><div class=\"lev1 toc-item\"><a href=\"#Linear-Regression-problem\" data-toc-modified-id=\"Linear-Regression-problem-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Linear Regression problem</a></div><div class=\"lev1 toc-item\"><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Gradient Descent</a></div><div class=\"lev1 toc-item\"><a href=\"#Gradient-Descent---Classification\" data-toc-modified-id=\"Gradient-Descent---Classification-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Gradient Descent - Classification</a></div><div class=\"lev1 toc-item\"><a href=\"#Gradient-descent-with-numpy\" data-toc-modified-id=\"Gradient-descent-with-numpy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Gradient descent with numpy</a></div>"]},{"metadata":{"id":"PjOMeCoHHlzQ","colab_type":"text"},"cell_type":"markdown","source":["# Using Google Colab for Fast.ai\n","\n","Welcome! Here is my one-stop-shop for getting all the Fast.ai lessons to work on Google Colab. I'll be updating this as I work through new lessons. Let me know if you have suggestions or improvements at @corythesaurus (DM me on Twitter).\n","\n","My general workflow is to open each Fast.ai notebook and make a copy of it to save in my Drive, so I can add in my own cells as needed (and save them for later!). You can do that from within Colab: *File > Open Notebook... > click on \"Github\" tab > search for \"fastai\"*. All the notebooks should be there. Once you open a notebook, you can make a copy of it: *File > Save a copy in Drive...*. \n","\n","Finally, make sure you've enabled the GPU! *Edit > Notebook settings > set \"Hardware Accelerator\" to GPU.*"]},{"metadata":{"id":"77tchMjPHSkL","colab_type":"text"},"cell_type":"markdown","source":["### The contribution of @denis-trofimov.\n","* bump PyTorch version\n","* make utilities quiet, less verbose\n","* unite install commands in one inside some sections"]},{"metadata":{"id":"ArPdbxB-vl9Y","colab_type":"text"},"cell_type":"markdown","source":["## Installing dependencies ##\n","We need to manually install fastai and pytorch. And maybe other things that fastai depends on (see [here](https://github.com/fastai/fastai/blob/master/requirements.txt)).\n","\n","I will be referring to [this fastai forum thread](http://forums.fast.ai/t/colaboratory-and-fastai/10122/6) and [this blogpost](https://towardsdatascience.com/fast-ai-lesson-1-on-google-colab-free-gpu-d2af89f53604) if I get stuck. This is also a handy resource for using pytorch in colab:   https://jovianlin.io/pytorch-with-gpu-in-google-colab/ (and his [example notebook](https://colab.research.google.com/drive/1jxUPzMsAkBboHMQtGyfv5M5c7hU8Ss2c#scrollTo=ed-8FUn2GqQ4)!). And this [post](https://medium.com/@chsafouane/getting-started-with-pytorch-on-google-colab-811c59a656b6)."]},{"metadata":{"id":"zfndtl8SImbL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Install PyTorch fastai\n","!pip3 install -q http://download.pytorch.org/whl/cu80/torch-0.3.1-cp36-cp36m-linux_x86_64.whl fastai torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KoM3dhqdM8Fh","colab_type":"text"},"cell_type":"markdown","source":["### Special additions for particular lessons\n","\n","If anyone gets KeyError: 'ffmpeg' running the SGD notebook (in the animation cell) you probably need to install ffmpeg.\n","Then restarted kernel and it worked. "]},{"metadata":{"id":"XVg5rQRtg-3u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"6a1c1b45-f80f-4973-87a2-601312cb1e91","executionInfo":{"status":"ok","timestamp":1536315764357,"user_tz":-180,"elapsed":4961,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["!apt install -qq -y ffmpeg"],"execution_count":2,"outputs":[{"output_type":"stream","text":["ffmpeg is already the newest version (7:3.3.4-2).\n","0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"],"name":"stdout"}]},{"metadata":{"id":"MgvJGuuJs_tL","colab_type":"text"},"cell_type":"markdown","source":["## GPU setup ##\n","Google is very generous and gives access to a GPU for CoLab users. Make sure it's enabled: Edit > Notebook settings > set \"Hardware accelerator\" to GPU.\n","\n","The following is just to assuage your fears that you're being rate-limited or otherwise; you don't need to add these cells to your notebooks to get them to run. Just make sure you've enabled the GPU in the notebook settings. This is easy to forget :)"]},{"metadata":{"id":"zY2AAO03dxWv","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","from fastai.learner import *"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U8m_trxRdxW7","colab_type":"text"},"cell_type":"markdown","source":["In this part of the lecture we explain Stochastic Gradient Descent (SGD) which is an **optimization** method commonly used in neural networks. We will illustrate the concepts with concrete examples."]},{"metadata":{"id":"BzD3lnRedxW-","colab_type":"text"},"cell_type":"markdown","source":["#  Linear Regression problem"]},{"metadata":{"id":"WijYHkHKdxW_","colab_type":"text"},"cell_type":"markdown","source":["The goal of linear regression is to fit a line to a set of points."]},{"metadata":{"id":"_07TImFGdxXA","colab_type":"code","colab":{}},"cell_type":"code","source":["# Here we generate some fake data\n","def lin(a,b,x): return a*x+b\n","\n","def gen_fake_data(n, a, b):\n","    x = s = np.random.uniform(0,1,n) \n","    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n","    return x, y\n","\n","x, y = gen_fake_data(50, 3., 8.)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0qvXas1AdxXG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":279},"outputId":"dcedab8d-3fda-4c35-989b-560299974e31","executionInfo":{"status":"ok","timestamp":1536315769862,"user_tz":-180,"elapsed":1144,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7fb06c4c2d30>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"Z-y6zSZidxXT","colab_type":"text"},"cell_type":"markdown","source":["You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error**. "]},{"metadata":{"id":"N5uvor4edxXV","colab_type":"code","colab":{}},"cell_type":"code","source":["def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mbIfi3GYdxXe","colab_type":"text"},"cell_type":"markdown","source":["Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."]},{"metadata":{"id":"MfzkrkBedxXf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ace9d558-d0c8-4066-d91e-c27b5ccc3cef","executionInfo":{"status":"ok","timestamp":1536315772150,"user_tz":-180,"elapsed":758,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["y_hat = lin(10,5,x)\n","mse(y_hat, y)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.29358931545332"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"-jR0ubncdxXn","colab_type":"code","colab":{}},"cell_type":"code","source":["def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7CgURw4adxXv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"57ac461f-5944-4fe5-8d93-56c1b4a87281","executionInfo":{"status":"ok","timestamp":1536315775122,"user_tz":-180,"elapsed":1409,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["mse_loss(10, 5, x, y)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4.29358931545332"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"XK-bP1_tdxX5","colab_type":"text"},"cell_type":"markdown","source":["So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."]},{"metadata":{"id":"psSo-snYdxX9","colab_type":"text"},"cell_type":"markdown","source":["# Gradient Descent"]},{"metadata":{"id":"FugvHoSHdxX-","colab_type":"text"},"cell_type":"markdown","source":["For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n","\n","**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n","\n","Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."]},{"metadata":{"id":"o8rd0N0jdxYA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"de7efffd-3734-4731-d8e9-6de4c5d6f35e","executionInfo":{"status":"ok","timestamp":1536315776986,"user_tz":-180,"elapsed":1565,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["# generate some more data\n","x, y = gen_fake_data(10000, 3., 8.)\n","x.shape, y.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((10000,), (10000,))"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"liMBbIoGdxYG","colab_type":"code","colab":{}},"cell_type":"code","source":["x,y = V(x),V(y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s-NZz8XFdxYO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"843e61d8-8a29-4196-dfca-b9a380c17043","executionInfo":{"status":"ok","timestamp":1536315783094,"user_tz":-180,"elapsed":1340,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["# Create random weights a and b, and wrap them in Variables.\n","a = V(np.random.randn(1), requires_grad=True)\n","b = V(np.random.randn(1), requires_grad=True)\n","a,b"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(Variable containing:\n"," -1.0550\n"," [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n"," -2.4389\n"," [torch.cuda.FloatTensor of size 1 (GPU 0)])"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"XcXg5T3tdxYW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"c1937a8c-8678-4653-9366-5e3ccd0373ff","executionInfo":{"status":"ok","timestamp":1536315794255,"user_tz":-180,"elapsed":10888,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["learning_rate = 1e-3\n","for t in range(10000):\n","    # Forward pass: compute predicted y using operations on Variables\n","    loss = mse_loss(a,b,x,y)\n","    if t % 1000 == 0: print(loss.data[0])\n","    \n","    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n","    # After this call a.grad and b.grad will be Variables holding the gradient\n","    # of the loss with respect to a and b respectively\n","    loss.backward()\n","    \n","    # Update a and b using gradient descent; a.data and b.data are Tensors,\n","    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n","    a.data -= learning_rate * a.grad.data\n","    b.data -= learning_rate * b.grad.data\n","    \n","    # Zero the gradients\n","    a.grad.data.zero_()\n","    b.grad.data.zero_()    "],"execution_count":13,"outputs":[{"output_type":"stream","text":["156.49072265625\n","1.163103699684143\n","0.16317737102508545\n","0.14135733246803284\n","0.12927672266960144\n","0.12000664323568344\n","0.11287008225917816\n","0.10737579315900803\n","0.10314606875181198\n","0.09988949447870255\n"],"name":"stdout"}]},{"metadata":{"id":"n6jPtFX3dxYi","colab_type":"text"},"cell_type":"markdown","source":["Nearly all of deep learning is powered by one very important algorithm: **stochastic gradient descent (SGD)**. SGD can be seeing as an approximation of **gradient descent** (GD). In GD you have to run through *all* the samples in your training set to do a single itaration. In SGD you use *only one* or *a subset*  of training samples to do the update for a parameter in a particular iteration. The subset use in every iteration is called a **batch** or **minibatch**."]},{"metadata":{"id":"_W5UesfjdxYi","colab_type":"text"},"cell_type":"markdown","source":["# Gradient Descent - Classification"]},{"metadata":{"id":"1UYDb0BUdxYl","colab_type":"text"},"cell_type":"markdown","source":["For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n","\n","**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n","\n","Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."]},{"metadata":{"id":"6ib9iLSJdxYt","colab_type":"code","colab":{}},"cell_type":"code","source":["def gen_fake_data2(n, a, b):\n","    x = s = np.random.uniform(0,1,n) \n","    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n","    return x, np.where(y>10, 1, 0).astype(np.float32)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tDbLPDCedxY0","colab_type":"code","colab":{}},"cell_type":"code","source":["x,y = gen_fake_data2(10000, 3., 8.)\n","x,y = V(x),V(y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sAzuVaeSdxY6","colab_type":"code","colab":{}},"cell_type":"code","source":["def nll(y_hat, y):\n","    y_hat = torch.clamp(y_hat, 1e-5, 1-1e-5)\n","    return (y*y_hat.log() + (1-y)*(1-y_hat).log()).mean()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yrHLRtYIdxZC","colab_type":"code","colab":{}},"cell_type":"code","source":["a = V(np.random.randn(1), requires_grad=True)\n","b = V(np.random.randn(1), requires_grad=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Weon4QRBdxZJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"collapsed":true,"outputId":"374bbb4e-2910-47c4-b01c-273bc9d7b586","executionInfo":{"status":"ok","timestamp":1536315810572,"user_tz":-180,"elapsed":7316,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["learning_rate = 1e-2\n","for t in range(3000):\n","    p = (-lin(a,b,x)).exp()\n","    y_hat = 1/(1+p)\n","    loss = nll(y_hat,y)\n","    if t % 1000 == 0:\n","        print(loss.data[0], np.mean(to_np(y)==(to_np(y_hat)>0.5)))\n","#         print(y_hat)\n","    \n","    loss.backward()\n","    a.data -= learning_rate * a.grad.data\n","    b.data -= learning_rate * b.grad.data\n","    a.grad.data.zero_()\n","    b.grad.data.zero_()    "],"execution_count":18,"outputs":[{"output_type":"stream","text":["-0.7053936719894409 0.6646\n","-1.088179588317871 0.6646\n","-2.68908429145813 0.6646\n"],"name":"stdout"}]},{"metadata":{"id":"oooUHMwxdxZT","colab_type":"text"},"cell_type":"markdown","source":["Nearly all of deep learning is powered by one very important algorithm: **stochastic gradient descent (SGD)**. SGD can be seeing as an approximation of **gradient descent** (GD). In GD you have to run through *all* the samples in your training set to do a single itaration. In SGD you use *only one* or *a subset*  of training samples to do the update for a parameter in a particular iteration. The subset use in every iteration is called a **batch** or **minibatch**."]},{"metadata":{"id":"-kYGfjyQdxZU","colab_type":"text"},"cell_type":"markdown","source":["# Gradient descent with numpy"]},{"metadata":{"id":"nZPBWWXRdxZW","colab_type":"code","colab":{}},"cell_type":"code","source":["from matplotlib import rcParams, animation, rc\n","from ipywidgets import interact, interactive, fixed\n","from ipywidgets.widgets import *\n","rc('animation', html='html5')\n","rcParams['figure.figsize'] = 3, 3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-CaB3dVhdxZc","colab_type":"code","colab":{}},"cell_type":"code","source":["x, y = gen_fake_data(300, 3., 8.)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yGFnuJHFdxZj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"fae6ec40-f536-4603-d816-60ce7bbb14ef","executionInfo":{"status":"ok","timestamp":1536317664682,"user_tz":-180,"elapsed":774,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["a_guess,b_guess = -1., 1.\n","mse_loss(a_guess, b_guess, x, y)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["81.64057739556297"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"sUnjxtmXdxZp","colab_type":"code","colab":{}},"cell_type":"code","source":["lr=0.01\n","def upd():\n","    global a_guess, b_guess\n","    y_pred = lin(a_guess, b_guess, x)\n","    dydb = 2 * (y_pred - y)\n","    dyda = x*dydb\n","    a_guess -= lr*dyda.mean()\n","    b_guess -= lr*dydb.mean()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sK-FdBaUdxZu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":422},"outputId":"c2551da6-b506-4157-eea3-f5504f292fec","executionInfo":{"status":"ok","timestamp":1536317670029,"user_tz":-180,"elapsed":3625,"user":{"displayName":"Denis Trofimov","photoUrl":"//lh4.googleusercontent.com/-5mI1PahJKgY/AAAAAAAAAAI/AAAAAAAApTs/jE-MakZklpc/s50-c-k-no/photo.jpg","userId":"118344610648363214086"}}},"cell_type":"code","source":["fig = plt.figure(dpi=100, figsize=(5, 4))\n","plt.scatter(x,y)\n","line, = plt.plot(x,lin(a_guess,b_guess,x))\n","plt.close()\n","\n","def animate(i):\n","    line.set_ydata(lin(a_guess,b_guess,x))\n","    for i in range(30): upd()\n","    return line,\n","\n","ani = animation.FuncAnimation(fig, animate, np.arange(0, 20), interval=100)\n","ani"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"500\" height=\"400\" controls autoplay loop>\n","  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAvLG1kYXQAAAKuBgX//6rcRem9\n","5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTQ4IHIyNzk1IGFhYTlhYTggLSBILjI2NC9NUEVHLTQg\n","QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n","eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n","MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n","PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n","b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MyBsb29r\n","YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n","ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n","bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n","aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MTAgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n","aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n","cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAACBbZYiE\n","ABD//veBvzLLXyK6yXH5530srM885DxyXYmuuNAAAAMAAAMCdMWy7nddDaYdgAACogAhgFY4fsA7\n","l4ADnaXr5MslRxHznNF39jnZ8116I+Fi5QfiJ8z5pwoKYvXucmR+kIsr15//TOwscAAKphgeG7HZ\n","XUdOTVpNp+iwyQKFSFXj0lMSg4xWd/hqVRURztr4xqySuJ7rysYL6riZbe2TYbBRgvBzwTCfXgfm\n","1YIzXRiGtrTUmo9P0KTQKzWv4RKmOrmjdtjBFCRW2wZbZPkyEhAlvhuBCNj0O/S3rprbF6K7P/9b\n","x1jANVl9nAqkB8JQs0jbXZtBB4X/ITM8kc/Kn9BvTkfUYPeU9DIQRsAmz5UNna0zX8DurpfBct6B\n","E+TEPPtlJqpzBmF/LAoDt3dNmmJ04hxHvhc6z7C4JRcrKLKnlWWISY6JbuMLeV7+Czu9cvB3XP46\n","ezrsS7tdIPROm2+cEYhlT9ayqmkliBmCHROTp3Vltp/3hImBJzJzfObx+00Uv60ssBdCbzsHvNxB\n","QYoqSWY4ovkNpGqY0JUqcXJ4TpSqtuORJN0R0LuH4KPJoGjLESnWVibp1GdP8kAiuqP2gZcWCMp/\n","UbkVn/Rt/lHtSXkiWq9swh3hHH2ywdjrHx9Qao6RT+1Se6UDelMGRQPqL2as7+GDYTrymiPUdXBo\n","lKkBra7tMs1kwsgKwOol/PjtGPFV3r/Qc+Y3qIoK4eDoyarZ0b4VwqOlli2fshqXjACOLdoLq0QL\n","3QcYcyH2F9qOdVkHy4vhzjz+zVIHvhT4ujPHfkRwjER2L/Nj6uMhSKnKG5c7DvwqZKDmGodhYokV\n","YCgJhU32rTKcs0cdhbtv2x2rD2rHJ99Dj027Nf/tOe75p81ao2NTOuR4hHv4SBkhf6xXUHRwl9iq\n","dzadFlEnuY6X5MjZ2qkA5ajIUZGr6IEsPvYwGcfw101/ga8HWdBzjJzyxm/tCYK9NydcNslfeJoW\n","iBGvUuNPuACvMJcn2nNe3Q3zes0pE00Z/9WSDC8yWHPNsaSoEjaa+fKyizXSr8PNwghu6/EY2ILF\n","z2sFh80VtWkLToqince1iudThuIn5PErbtsPoqkalxLhQb+gURPMq0MK9OGbZAK24zIFy8Lht2Ed\n","e/ZM10Q/4NHgz1YmHC+gkr2ygRWX+YF7KgcMH4vhGWt35f3lyE4zKvKJw8KxNlK8xXZ20nz7fBM+\n","iEbXuzGn8/r0Y+Uq8LzbAG2t905+7PbWX9Y8N0MmInAWaZeBRVNnTVLiJ5kA86Y/FvvOVjyFsKzN\n","FSsmNhCgLdxJmC4gvVBQhqHL1HtGa3I3R+vO6bIi66sTP9Pf4SGwxH0Mlco90YzpMjrH/Ob7HV4p\n","UPSoHVBPGZKqJ5fAqP5UglD0Htjmh6z9BIgLVD4pc5OgLUZXsk8ClMsycsvMvYsnrCG92l3jQr7r\n","kUXlwV6GslY3rBNuCjDcPmO2e1C0LzNqxBqVZ5vLk3rTwJ/7tEA63dC3XBblA6ZiWM3+otOiBd3d\n","FBjz0nlc5UCf2gwXSHcKf1MEMRCzLWIofhR9fHjBH8p0jadJ4H3Ybp6jBq+ZnPio/qAYb63+o4PD\n","tOqvYbAl9Tzyy2ljuDpnHFTccqN3rM/Ixmo2FNweJkDAhoK1GVC8MJKE9zdG0RV6rkJEt50q9acJ\n","V4AiMKL6DRaqlAHPqLdWIjowZEAinN96xiescV/MbSNt1IThQslVGS5lwpfIHBKeJ0jlAd4uu4uz\n","JYmI9Xr+jH9pCYMyPAESNMYya/jriQJReztjk8Xwhyb48QhhH5R4K1fAQKwT7buL+MxmeQBrWGa+\n","LohJC3n3eWdFcVHG8OFOy9MigXw16S2CLFhTYFhn/YLrfNIEjUbdz/v+jlRKJBN6Ay2zQJjiDk/g\n","aQ6peFC2ZWW87tBEV2pu8r967KH0xkLVo+nxOqac28t6nufOXgmOqslw7NckXqiOfyc6H26XLhSv\n","/tSCIIkV8CSffg2zNSSoyRixoi/J7K3XrSNHXMbIM6ojDLk4BKuBxC4feJMqweVzYpiDvbvzwV+K\n","pX/sfYWFa7vGrqTSYEmKYtggkjykzT93lcccw8SBRbx+GcLMbGGlx/tS3kZyZZDqDTAVcLivXpVG\n","M6+Ufq9h71olq9I2smj79NaGI41ZstBnIvpuq37X/P+gE8+FXLk5B7ef+InEFfiK64uzM4+4RpxR\n","6jt4r/y83JB030AO5Qr03JsvytNAduO97qC9yKEQBH1HiLX9IzJKkbSIwNtsRwGWOa5pAC5TuLim\n","okoFYtD0yQ0sqUvAgMnmr4YFqHpWpnSEnRDxp1yRFbDQASQ9DX1mePaOan1t30o7xMbwb3U2U1Y6\n","mlXZVDmp7OcRnDUav0vM4V34KmP/d4hNFwnFQnYieXPY6XC9CxWI2ZvEhUgB0jxZHFDA0647za26\n","SjQEfyVKAOKuiqxoF7Cma6xtr9r8OYeAWTC6POeusSmXfI3dkwuVU5gMyj5N/FH/CaQt1c0lz76H\n","odMbtTzbjMjn7JMNiGwQrZoaDcUm2YpqAOvJFp7/V/YRF1WWKqg+Riu2pmlAVEnVYIeb5JLiE9Xy\n","z1zNqENvxNkz7sQ0zovv6Dc7x/Z9/wRywSWKgh/B6CizWlh4z2GiRkOATyLDM3i/U/rUxZ3Zxk8Z\n","OqOdZTuHTJy70ZGKgbg3NIywsUwYnIB+8ttGAK9rBPzipcirzrN4KYZWXScm3HQDehyLBaU58oLi\n","nLc22QcUe+A+gy+5KlAlVHIVAyumRh1pA4PzRiidGs4CYdVnlIQ7gwkbmkDIaAX18lUt2WPCB+BT\n","Y6uqVUrE1V74xLy2i80VIg893ZHW6l9BXklQudI1qVeeKD+otpGQmilMGtQT+Yy1on1s8xRZDr/D\n","U6GeVoGBNBtAraXSoCiBwfNulCwpf1v+wLVd4oJBrzqfwPh3Unq3ntxH1mNPOnjwLBk+k5nMApfD\n","GggZEhMjneFGhUtc2zHK8UWKZYsnWU55OyRhlDkFnr/6Av32Xa3G3bIX0V5qSEvVuedmIqIT1176\n","l36LCMTVZ0Qypvl+kgrto6HctIjA5G6j6YusfrSkP01VyFgOSqoErFhgFsi/mctCZ7UDQsHlDdL6\n","ynMcRV/BXKhw0yroOy1MZ7CtIWIxgtYHgb8KaFFkXQSMxvxzBLrOnu9eQGafs8BP+lFLq3G9NeSR\n","LWPeR0SB1t2eoGMjNA4p6mrPxSUnLeh6bRirPgDSvBe1wDYxZEY4kCf0B5ZOvg0uXeaEARDVVLV8\n","bb+bK39tkX3WcARBAPbhqD//dzMOxF8v6zHXHkUnYzkJrSeBOk/RseodtxnSvvX1/xvRVENgwd9K\n","1FE6cKn/Cgs+FaFh4AGAsYhUja1Yt/XV5Vdc0hla4xUCwYn634vqI6W+0TTNTyEG5IBJK+Ld1M5v\n","ZPTQNnFCh++apA+GJBDGSjY2UiobigmZzamBHhPDo32YAExDdgjHlfrLwX+yTAereZALCLE4ov6e\n","e6TW0VwlVA163X7misbcPbqIozQODKJDswtNwmUmtbg6+mP0u8VY3DTY8IvG0geOS3+8RPSMKO3l\n","JFjuiWtq3BnivMXbFZ+ymCmH9A6dMOT29Golc3WfbG+s1x9vG7uaUoEUOt6SFNm17r+Ar8J/FRfm\n","W77uq7vnMwfOc81FOxHjF1X9V6rzGCO2QDGY35HiBDe1pJTFhmTAcAmKMm04k94gXFxMEam8kO9w\n","mIjeK9KEo2OluDaGpnW0b6YIFMjBp7fqneUZQCaHl6K6FOQQOdqmZ/tTBc/TibB8SYSNmWRy38/G\n","LU6tWRhiS5yfyGYmfxsIqN+lCdyqpoLe6oGVo58yQqAM+bPPR/G8HQiTiyUXnlDbl8zLSdnvcZyp\n","H63NVN94ylDDWzFKpPNWGyVmuieud7B8LrzkJBA5O8wJ1lRYkP99GW0ehmOv0iwwOYDHI0TCSw5g\n","ixVNwPkekiGWeZLtHleeUxWALB9CNSd9UN94kqd7BQ+pBj1kP1tR7NvBe9sV+gxtIEOnyUcTh5eC\n","6/6jJXujNx9pwKnk2sYUXafgEa9umu4nyc8U9XRZ53efNHcDY093MovEI3ZmW913Y1ps1gYigDND\n","TKSI3zYw/7dZnmmXz9hOcqEFfpvtXdqrfZHn7A3DpQeEtGJO9/OktImw3ndBnVs/fbGZ55AYfTyZ\n","weac/d/77IAx7aQskDUB7CCydKU5UVdn43jS8k3UVW5JdlNPqM6vAnQ+f10dDvulFuPwXNb7j4Wq\n","YVlxxTMHSLL49v6uzjnOc7Paa2xK7vgZG3NARl//jmCP/lockadr+PSaKB0AT0j+VoxnLCuPqRhb\n","nYfaAwh8yPBE9iQP+iMcgxdoLpy7BxlATS8BatdtxthLfMEh90oRwtLQp0Jgy1i8a/dX0XXlYeFK\n","FJ0O0vmezgxs4GUQH69cvESDDZuoPN3IbU7NgY0f8Pa49BeubtS0SZyigZfzAS/BQ9XHpWRqYGQG\n","Yo7hK62co1r5iPJkC+3eGb+rA4x+Q6ziRZ4SvTASRdsC/46Xbg/OXp1lpjMgeb3KU5L+ZEFFJFrd\n","92LbxcgOe/CkpY/oRqft8qWbP/r8QZ80fs06R83TyLNjSsp7bkOk9K30s5evkueozTxjdLeAY22P\n","LA/7WwOUO99d8aMUfCdCjlqipGbvR0cut3i9aeZijTu9ASmqS9BAn360SSgPiPJYh/+PdscJMtkP\n","fzWTLEeHcyvvGPUJCl+GNvr5be2jEmAIBZ7McimtsGvQ00nf9pYcNA8ZB5ErDZiajOMZbuCZS/Ue\n","73v0KHWGGKtii8ELzWte4xN8ETftQ1AO1dS8xIsBsAkpWye0Dmei9qShiLL3qCgzMIErkVUFJdMq\n","IpHG7YG95QwGo2BHlHArg/ek+SvHHfiT1T0kJj29UX0bcfL+5Hc9D1KXaDR1oG3507SHAt/GT3Ct\n","+3gUwHYc4CPUKt8o+Gvg1th+zqfq+ea6WLRfCaWViygBsppLUSntiwdZKZaP3AWpBcM7o9dc7+PA\n","IIoUWxHvIiQ85MQzEvoqJa7i8B7K42lGMLwTtXJr8XmSNDg2fgKkk/m7IVjZ0meEx7YSt7sjTtUK\n","wadh9v/IBajw7nQxUJYbHhtPyD9O1R9t/xHJcdKL/UWuV8I3+4jxkTIf9MTH5IOu1pXf/Js+K71K\n","FsaVgAftn193eAHDT1MiPZJimTu0Sc5UIZgvmyWP9SrevBawXk8cLPLF6sko846/1MgrhUWQtNco\n","4GSPpQgdco05b5QmCAaJ4JMUePLe6JSTNYNcjJXwYSdakbNZ9w5bYJXmqaBH6iZ3dbNJh1W9Dzkj\n","GTAp1857XP6MEIo+q+BUfwGh7iTprE6Gl5Id/rn+fqtpawUtsLsinKTAHUv2dAN6OxOWV/SzLTIB\n","mEkRvaaU2/V+rwdxtpRnIthM2nrc+Y7zqa80RyvJXaP2o8l7s1yo044BTrZ1AX07DvK72uUBT3M6\n","iGL0dRR6w4418xofCwVXnXSuHx8mcOH711oqRSpbJQP8aDfdB5RbFHlp7pIfSw8YrCpD4jAKpfJV\n","euPsaKTLpHYjcnA9xkG4LzWCWZomD/NPjON5kPLFlplPefDO59z0ckrW4/ajWZSzClTYkQitVpt4\n","B0dCcYUyoI8dKj+K4+8VinPiZJVdOcIC0GCC+ghCxIWMu5QhqZsyL0sNeZTMh/q8msqrdwnSElgL\n","mYQblwq/hJwNkxLBK/10IuQQYlnWFcfst2WSROHSW0CNEHpfQL79NB1LBz7h2WT8nOS/pNwoLYs7\n","vrxnoZSdbfEbVvva1GyTChHjMDzkWeaTxVc/unqgvqOWxWD7yHdu4bMMVYlh5xHXUizwadJezo04\n","oYdeqWZyUdSvRybg5y9WI7JrMvufZTWFXd3d3u6pnX+wYWF689cXz5GfjNk5oYdjoegqO3NZ0mtN\n","rkAlA30RCnNkpJZfobu/CamWWcDwLIaEpFCNa7K+9pL7sFiXDhlOIMYlApx2MoP4/okIhKBkIbET\n","hYe14CojGoFguShcfKxyQsZ6IRq278gBaf+FESl+gOrPn+htFd25OCwCE7R+BOhSlmFXuOmVQVL/\n","wvuXkGp/kd+QpwGBBYQaMs0iYSsDkc/A3IJ7aZ0vpT4Yv6D9pK5lzdLL+7fEoPpBm7DD79JxVmjt\n","XxB5q/igb57xSwudRv5233SXJt74xD5LJytB2wIsFJDVzSSPui0u+7aW/O9Rym5aJYHPje0409k/\n","IN6qRxk6r6bLFKTMPSsndhBOedBuTj6YddHOg1G5GhvQrBmzc2gnudjX1PQ0zYWpSikUnJi3DRp7\n","FeJ0tv+eD2gqA074v11Tbbo93ydomxe/X4EBl/F1zHhbBJAp8nd+IPSV8uA6qVBKxz8K8f7Cft3Y\n","B/l4KXJt5yVYfT1S6+v7FLHrfvHXy2fePuTU+4olF1JXVHR0PpxRvjFaSkoahzeluTtT5SfEMQHe\n","Jmh8ghjzHqeJWAzLEGUF9/BoCD9bdfMznLaxtbjHEmir2u8XGvo66UlUzuNTY9tQBjkLHRhnEapO\n","hJCyFt63ZukPgGBYLhwy4c/BimsDdnl6MPXvsobUP+fiEnedfr5sF3EgDnLlqMnbUf1pS9bWpBtC\n","8jsfd8yPBekkMExPIyxBaB6cpq26weBr/C5vydxTUP69t9llPZQAV0cgDBlbOdKuHCTN60YRNYea\n","UtdAJVBWEZL1C/Ucr1rndLyTqXr4EWRzFYxP16ONEutsI+ZCb9TFkL56syrPgRIr34MvuhCAxdpE\n","R3zjloHpklsispyK6VrR+q1+1qDQhBGt94UihJGgfUqz34YTni4IC59v8Hrqd13cTe1x7zzuL0O/\n","CLunoZTthKwy8BSGvg1OHMacb6172EByM9WkAUFn+eaxlilLTUoZ6/emYAMKU/L/AbNING+YCw2E\n","vSzx2vRhRzSyA1Tx/EYsc8wFGCg/ZyIYZwTbFNUPKl6mN6TG5Ka9FK+A71/XlQTshiu0O1ebx5iM\n","Zren+yBg/IXyJE48dTg2nOfIhcGr7Pf2ph/AWBfqQ1c7aiBcL69qoUzFLbRDLvqwD/LHSVVYBg30\n","/Rg71BmZgaeK02N3eRnz+ghpkjbLDXs8jOwL4z5PzLWtH+PmRuK1iyAS685kmpXGXepv2jm6jLSM\n","2CDyrGrIpuXwRhds8G8NvJLzueSfgISfdKcxrzUyP3WIM5s4nAYQp3x2Xj0KChvQZhkith7bkJF1\n","PPELQHCIFSzcLKp7s+sekOF8IvW7B7G+2h1ZWwIUctIPnzYZkeuKtlLGM/voODmNoV4NVTkMfrx0\n","THvkm0Xs3w86ARbHupURIwjlNvznqMICgjCYueNyryVfdMgzomUv1aiUkBVOzy7Zw7rrF0V08h3c\n","Qpo5dz5ZvZG+hJhu/u9eMGnCHccOIgPFk9Mdj37t53QNK1NL17isyOw47iH0y1yaFXPjTw/TNfD5\n","aTyJe7D2sZk32mmi1TauiZZQCo/EbX8vVynifjnS55UmcXZ1MRI//jmXRJlFL3ooLrKDH7blsVum\n","+/SE1uOxWzqJksZ+QMQvfa8vGawjWJZjEy9EhWXye0LuqYTseHMLC4VNvGiKqCuYgxfeC//vq4aE\n","yNmTueUkifdNBBML4Sn4tdQ87joDc67lBcXW8WP+MJWXPVaYFkwPWCO0VTA8sAAlBQTwhFbKnBWc\n","P8J9U5V3P+nmjJDba9U0xBMYZRjWpBwqWJptCVZRPLNmDxLCUs50O0aQ3adEuMIJiJKTbHVwX1ii\n","Zdpt1Y7Jg82h/n373/G11Ky0ClaG2QCvCHaxtKqJHGWv+D0E/cw6axSC/t8LWS5XZOqS5bUbU3/1\n","QjxjCjeuztKnTjGMkmf885U8XGulMmsFqUqVx9cGXscK3BkHw35W//0U2+6n59iQCv/HlwHxE38Y\n","WxTxWLmQhcnb0VGPRkSqQoqiBm3PK344cXxhjj+nx36jal9RSWB+kusGj0b5yx4rlaSmDhBiUvCF\n","k5ATyvpQBYV5KQr9EIopw22QL37EfcvQNST6TQNq9lP6dsVKIloeLAir258McxF5YBQNkiwxqQaf\n","3FQ40BQs8sY6ByjAMKciq/p0AfoSdBxXUKe1aEkzlZ1Nwjnnee1+fuBwifzIddW48Hr2fMxq1zi9\n","Oxg8OP5n25FDhyohIrjk5mrEflRjhonpanTJOltpHtJ9yAkFSSmVj799QAd45r9PYvnKOnhqlAZO\n","xm30oHhTxwuHEn7y6RR+DY04kJSzcZ1TbRpbTEIfunyH35nBM3GebsONKV+4mOQFNb+r60K5Kyzx\n","8GgicXoBkeJTT5QiXYtFliKwq5tr3C6N0A0hKTeBD6l2OCpH+B9ucX8TN2ljsdAWCqmOY4SrZBxL\n","YHTE9wc1qT8xJaK+qFhg8v1rYOPjAYVVB0txN2cHFpRcxet5evRh/uJYCQGFyQTHuL1rQHeyXVFG\n","LBs1g5OLyTMyrPujmL/Zp/nH70elxw66w5Mp3oUrN1WxdH72HtlccaSK1HHuOERvxzEl2k7S2C8O\n","ISAQAa1h2HJVz7sUSEzwZ/rY5erabyXcHQBfnuuI4lV14LPm/ybjqepduk4eag+t97a7h3lS6noU\n","4xCvD6lydw4IKG9mTvJ8PfYbdPf3d+7BVGRNHs5INI+Ia76DKChgelQaQw8OWHvD9wFoxEaLiAw7\n","gFdSCNuCsxSmVuBlKJI9+CILTg/F2E3wZVoRZ+U83fDiLu3T+5NPLAgABqx2M3Hzmbw/c5M54vNe\n","JaqeJY4pSIbScEIQurAEGiwPHCtbILR0jsPdeF9Vgd1CuHvDdondrBmhyzNj7dD/h0IJm4Xt5cHa\n","XkyJ2dFlMvwd3AVNvSB20ZxZBgUMSgKinsYSr/OaORzlPsgM8T6kJbkO0i27Fc0rJ5bNtn44xPG0\n","AwF89pvh9FsFHHhe4ANbVxym9DpfId0A+o3aPY0CO4f3sBsBbM+/myJn61/YddRSM9dFv02JZere\n","lmrPTR0Zg52ZK5jJqDaFzC8ORDA8/XKWCZGNYLdzdQkKWnFoW9cz76RYHZxNscq/Bo/pJZOcBZau\n","ubAvq4W9IpPODZaqXeFsJgOkIm5H60b9dQJrjl9lPXab4KWRuLHghXnun5k5Nzn05z2R7P8OisRq\n","zI/lyuQzOYC8vj1WxwX+XDDGg5w2YUXzM8bPgBXGhKdMGyGecSQAAbf1eNTcvqDoBWnmACli4fNq\n","5BZ4KCcXul/fToRmDecv2lltjO/UpWbwjI/kGYnW6VqzDvxbijRehNYdjhL9vmaubd9TcGHicFaW\n","Hj9mTnfnP6jTLeti09BxcMkKwXerJtghHImreLBC/A+NNAaD4cY1qOPVPsflHjwsryq9R6XKEC+q\n","gldPKN3ISrfwvqe+ESllpHnfNAJM7mmOxesp553pdpjDUrodmNUCrePqs01iBJtA/JVvGx8gvgx/\n","WFev5bxV6sFd2fiwRxyCd44SUK//NrzoPaQxbn2+Mh9rmT9u/I0bTZ3RIlYfc/Vh0Uiheik9vR3k\n","BNvGG33vNYohy2UrI9pnKUmCe2EfISvia6IxjCear2ZM+1yiWRBGUZ716rESprYMI5wpqnubcrzL\n","XUzru2CALAa12IJw7coU+/ylhAGUJXMiVUrLo+b4ggE6NUldvCmhNftjhbggwpf8eSZ20eVlU3SY\n","o3s0YOli0QlWBppvjmUUTaHAACyUtDy1Db60aLm2g8Mn9JtmyycVkQ07j3tbxtTIBWp9CTqe1EuM\n","OKCxUrRduJJT1egG4PnwDGOGpR1u6i5rEkKj1vo9ZAuLhmsso/QDdKrF1ooHP+rfWrRYHKYnUosQ\n","wrz8ljREzChWB7azyX9rgdDgdbeUUHdaj47xW99Xm+JUC+gcVGpa3RPBTbxWSheRziX0VqoaSsn6\n","jn/2jMCoDfPeR4QFQa/dQEqleJZr7VnA2F6lZmvbAcHER60QT0kChUQpBV9rcFtezs8EhAPP/Tja\n","xbIJ/Xig1TXVFs5NU9SikTIPbxwS3rx/3+nBtrM54b95lTIw3WA2wEjCKnGuLQXHEP8w5gskmK2E\n","BG34LrMPxMTyNfTj5fM+MZYKOjhh52hdg4u5kLTdaI5qLHIswv0SRg2hBedUBMrvZcN4zIZJe1EI\n","cjkKBCN+P3hKd5If77RBNDTavPZBtQIlMN0oXDhxV5MfeVhUt/ByCxnbVYD/i3XOZil5rLsEFbIl\n","S80n0Sd4F6k10IqVeVBzdUdk5gS3QCJa9iTelc38e0v8mpi0LOz6htTuadtX8pcya/BNuU1qTLIP\n","u1GnzDbF5vFNV4SGefupR71IMZJXxsFDSFEb21uN6P5HXZ5Od/9Q2Cc9sTttM3jUZNfRxCcAsAJD\n","mUhn85BEntPz9Vp6Xkcq5weTNCs9ZvBKqYpMaFfjRhsxswGyn/PbJ38W6l14NnXuuTJUdv2gvWE0\n","3SRFyvtUMiKLby4LX2C9hhz9syuTce+NjHpXckN07z717bxlq2D0/2+nPM1YGFmI0pNxb+YTsXPZ\n","OvqjTjvVm9s4epo3F3J1QBu4L2V3h4dUOzYi6SsG3p/V0S2MUD/dYySMxgYSMTVupPhOW7ely87Y\n","FkjVBop+q77azU29FjGR/B9bHmzFOs7hdEfoKITyf33h+Ur6IDNqnhufLUe29QhW7iwsoKr19yNn\n","VtLkGyoYsULEnoQuFceMSBjRk7GASod/ds0Q9LpIwlM+BNh2FIqTWBOCiWKm6QPveS1DDZy3cX0S\n","ArjBa+DaVXMgIQ8JvMazhf8/kY4ZggoNFcElSnrTNMXAReahFgo6UNeeJPQD+Bc1/HOHqAQ1YyXi\n","rM/6az3zSci1Czc7RZitB/co5mDImeCOQV1aWRdWFid4mA6H6+zZpSKGfhmy5ZgftUfaXhckvRmg\n","34Xwy8FUFzLDeaGa7pkMURT0lEhK86b0CxqfO0j348X7ffA7fB2bGh/VvqINkUY5ABNWTLtlIAaB\n","m20MbSdgUg1yFsJ/QEsvOZi1mQCAnnjJJZEYii8UvUFAK74SH5F9QNzCecpVwyqR42kN31qvnt8Z\n","OBz8/CM8nO5jAQllgAoJAAAD/kGaIWxBH/61KoAAjDJf4gCo6Hij/fpW5urSM6G6FtxDMK+9tKXq\n","0mJshbGvRYKSTikOOhi8RdZQ1t2vg6dfd7rnCP8I5LmnUv0BuQYvK9dWNxMhMF0x4Y97GKT5sGOM\n","xeJHI3MLOSb49YOlmBzWCLgPndCzTpJJN+GlzNAo2IzFAOQ/2U6bAHA1wz/IDNyi2y/EtqmgzXHl\n","iWQa6rWwKrwScXo4pu6Sfd5szKUaQjLY4kjwJ2NzK5jn9Sv+3q4SXBzhoejgKAsOgPUbh7wW0lsR\n","JjF/w1oR4D76NAbExi7Z7NsxkWMe3WfpgEvFGVN9vbixdHLdvvt1AT/5tYtLlx6XfdHh39LCqh3L\n","Bl283XN5TdpU0a/WGirweKJyi2kevwTENEB0s87HU281znxaIsKM++T4wcSlS2hQ2eM9lSnFbo8E\n","NlWv1uMqR1U8u+f/Pto5CtUs3OsDatFzqWSCtHT+Y6QVT9yvzw5KDg5U6Rlm0IjH7kM9TqSCtbQn\n","PRe0Xdx4rQamqqKHLkHBx/J4xFfpkxEIZ4ascZlq/1bHkH03SB3KQoN4kR6jYzhCWAyLv1e7I6M7\n","wj0Af835gi6uckbJCx9T5VRI/SVVtm7xGq6bKjL0a3a/7ojATQ9JLO9udIf4zBYagsNnJ/6Cm/77\n","xmAZ8nXkx757yj34341UwpqkJt9B875gTYluz8+P6dQY9NcZkPitKY8X6d1n09g6ZHrWXO8u9ET8\n","zkzTw1L7D5YgXzhWDw8rVaJyJIO4ZfuaH5f11gmLN8Enu+4pWkVOn6c39JKjGZT0COkdqPGx9Di7\n","d0QTGgXzJCsxC3BucG3gCm/0onDfMqlE78dkHymtEcgYHm/Bu+SRJh1Hetu++8qzlkK9QCvHtZSC\n","F+cKaY/Sju5FnmLdB9nkplcBkwhXsRQttQbwWvt2fTiyFnaraFgy2LTD1m1r/iN7/4lpR8Nwa0Re\n","HNGus2vME7htMwJr6gF8Ro3glE6pkBqZJU5z+jv4xmA8v1M9hpWafT623cv5jrPML6KYTyM7g9/X\n","Dbov6Yvy54UU32wcUFCSUQOJ1JCWg8UpO60SZsrv8GzZV4ktZYwpi26AmxxRdeu2cr9ESzwTAk5d\n","qykcGym/oVPP2pAxVweeTTwDSzj1TPuj8KhWq5fNrXDfMV+CUSBJghEE2tjP0a8pwiQL66GxK3Zz\n","x0LSQ+uMX82FH7WmZvDM6jQg6WnxXVcGRVCLhQEEiu9rq1xQmC75Sjm4zdrfr2boGU0I0x/JeiHT\n","gB/gq8lSAVwMErqNBR7JZtr159zbC/rXAqq/gXs0EgqqBncIHgsuoMmo+txZjRbEGwXWSkR33Fpc\n","WShYG9AKD0SPjvcb1UAwAAAAoUGaRTwhkymEEf/+tSqAARhVKO1Wnted1RtfUAGYYa5jS/6KLHff\n","wWj6FxCCCjCLD9S+zaPmJMnf17qYMpNhBXW2poS8fPLqi+qZBVtKtR5QSda1J/Wh4r6P9h6PA6b4\n","iwX4jtdwgbpH0B3AAGPVefodt5xhjoyT3JN+PehgxSzsgAZk2EJg+lvnuncg47sz1QyJBYNAQKJg\n","PVI5KqOQ0K2BAAABaUGeY2pTw78ABARVQATt8MsGpxpP0uIpvdpBH7f6tAC+4X/3DnS3bDnKasbH\n","5E9zSnWzBEcI/xV17ukCbtPwdwQWeGsvWA8i0ODTOl0aZO744Iu4a3XOW23y0O2iaAxJqm1w5y3+\n","aUIfoB6l0SutMYSSkqvt0B4Xo1KMAjt1BNyrit0UrDUNvxfARJeNC4uDmojC/TOQ7Cau3De3Lb0k\n","K4eBDbUXzyV9z5YMQXwQYgNwQ+xMB89op8skGWG/1mSMR1Ov3ggL8fJ94MpSG0dkng/rwDKA7pLl\n","BxQkL/HTGY7kl3oxfEAyqBf/DX125CL8JRTbdGZEC517ix+kxG32J219khhCUd6BEB3fy5NbFZw5\n","Pg0P09zClJaVJwE+aYEMeuZ2/Zy6SvwnV+LMn0PqkHIZH1/kvWLoj/hvNXJIjEjvuzUKiEeSAu8N\n","eDrOB+DIplcB4vgwbPUAFpL50UkphAsEg/0ZDRrwCLgAAAMQAZ6CdEN/AAXSJbnf20XgOAYAP6QK\n","jRXnO9+yGbx4jOzd8P6N/82zU+R5qS078D2qQrcDwn/4bkhcmv+a0i672KngJ7eLKwKgKCJJlH0V\n","T9sqGYGlmosi3Sh3kXnRp79v8qdRp5lUGyfd3MC+qs87wwhJwETdFqBo9MT8vJ7zhjxbSybcdJ1A\n","R9FtArzHMoWYEe95Y75PU8RRBpAH/UIUkFVnmJhGK8QbabXe/1Zyfkoe7h3SDmUN//Ls8wrF7nkI\n","QJswNg/SyOgoaYo3RVPbuX2Xxx3tueRUJFtqM257vchyFIg944n89aRyzrVmC3+kYfPZGfKhLP9k\n","4lqoQaYL3cIGS6F1XT779uOYRudew3GyIUTKQLj3qkPL2Gl1e8yT+BXWpLHan1BTtqXgWa0Vzts8\n","ZU/pn8yZ8kSW0n1AUEz2QTcgIVHwfphl2mN4wdv2kiZ0tTtM7Frodphpgf/FRHRN9cTLlh1lJ8MT\n","YSrZUjoo9krh1IY5CIiWsnmdYnJ1sGkaJiAreUjEmc+Rj2M0lgcZbz7SEt9qikkopDzurzHhtZY5\n","fN4KNOQCwJHLjjIaHTz9waeBTiZyltfOdGO69w5nAM1Q//7sScQAoJxwkjIL3jSP/Dl/aNUTfVVk\n","7J0JQk1uEzUvEwy5zmYj60T3KIHc3DA2YKrTDsj49wp6AgJFM0gtCqJJ2dHhJN0LzX5REGboYZA4\n","oKqr0hdhq3i4HYx5km3nh2Wdo3URXECe9swT8QyZsbUgKSk5uWLreX35eCU+GNhajEqRMYBcy9WN\n","mU3r3wbBB6l+Ggr0Yp6xXyEjdge5lhL1tsYZKidT0peF/Gs7mD2Ib8n7WP8N8HsA7i8gFhp3ddD9\n","0YmOG/hpT2KqQ56fvdwdJOEwyk662kC3s2baEiUeDutnDsz9KVZgQWbnEmdOD2KcleLdmY4hSurS\n","7MIes9zSgAAB4MWL+IlgXcddWac1lW/v0GQNaY6lb8k+f9EJ2QFsE5gIEyTNJL6ZSY3KB/+I4Y7y\n","/hGeqPCswvgqMQDDyQAWeg0Cp4DAgQAAAFwBnoRqQ38ABh5Srut5WWAEpruoqsBc3w+iZEu17ibN\n","idt4xWvO1lV6PwRJLZ13jJ5rGb2o03pyr54iorrY4qoKtFNY802ATSh+qmVQrIqevbrygwUxthWU\n","G2AQcQAAAKdBmolJqEFomUwII//+tSqAARAv5Lg8WYgA3ZGcjzncY2giK/k6EgyxAST5h+72Xv4h\n","MXWgJ6NO+vWRZfnkjeDn0u59HHPfE7681KcKfZ2DCnfXCIPc6wzqWGSDkwRpsnVHq4wYTxsO1iQo\n","WI0xg/R23LMEwgj+qfbcrDeVkW8rvhBzfzaodIVH6Tyv7hf5QawqTBTrIS4G70rgBb2vhoemgIDg\n","DwCtgQAAADpBnqdFESw7/wAEGlrYDoAJaOLZT9uw9HWK7KTeKKYbc2SzExafVX4M+EE6t1YlaYqM\n","mOQnvv+FAANTAAAAKQGexnRDfwAF4+yCJdEAJqR160Cx/WWpMg2FU5qkALY1BjEoT+s9wAELAAAA\n","EwGeyGpDfwAAKOnhvbNdPu+piNgAAABbQZrNSahBbJlMCCH//qpVABKD65QFwxtR5u0IOOgSdSpG\n","SXIaVborx25rpu3deNJl2/Kfc7OtJ7nm3e8s2rMyYlNoUer+BQ3b9cS567kLM1CRePjN4BYLUr2g\n","CQAAABpBnutFFSw7/wACEOUGot1b+BdZl3bPYqgd0AAAABMBnwp0Q38ABfer+jEO3T4A1g0IAAAA\n","EQGfDGpDfwAADdF2HcvPfg1JAAAANEGbEUmoQWyZTAh///6plgAIQjdDgAt66C6fziXqkUg2sgK4\n","VlwTte7hXfIK0vz1xrsACPkAAAAaQZ8vRRUsO/8AAiDlBoLdW/gXWZd2z2KoHdEAAAARAZ9OdEN/\n","AAANz1gB1RL8GpAAAAARAZ9QakN/AAAN0XYdy89+DUgAAAAXQZtTSahBbJlMFEw3//6nhAAAAwAA\n","JuEAAAAWAZ9yakN/AACjzA//jBZ4nkiBdLQqYAAABBdtb292AAAAbG12aGQAAAAAAAAAAAAAAAAA\n","AAPoAAAH0AABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAA\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAADQXRyYWsAAABcdGtoZAAAAAMAAAAAAAAA\n","AAAAAAEAAAAAAAAH0AAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n","AAAAAEAAAAAB9AAAAZAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAB9AAAAgAAAEAAAAAArlt\n","ZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAABQAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAA\n","AAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAJkbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRp\n","bmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAACJHN0YmwAAAC0c3RzZAAAAAAAAAABAAAA\n","pGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAB9AGQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAA\n","AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkABb/4QAZZ2QAFqzZQIAz5+EAAAMA\n","AQAAAwAUDxYtlgEABmjr48siwAAAABx1dWlka2hA8l8kT8W6OaUbzwMj8wAAAAAAAAAYc3R0cwAA\n","AAAAAAABAAAAFAAABAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAKhjdHRzAAAAAAAAABMAAAACAAAI\n","AAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAA\n","AAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAA\n","AAABAAAAAAAAAAEAAAQAAAAAAQAADAAAAAABAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAFAAA\n","AAEAAABkc3RzegAAAAAAAAAAAAAAFAAAIxEAAAQCAAAApQAAAW0AAAMUAAAAYAAAAKsAAAA+AAAA\n","LQAAABcAAABfAAAAHgAAABcAAAAVAAAAOAAAAB4AAAAVAAAAFQAAABsAAAAaAAAAFHN0Y28AAAAA\n","AAAAAQAAACwAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAA\n","AAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3LjcxLjEwMA==\n","\">\n","  Your browser does not support the video tag.\n","</video>"],"text/plain":["<matplotlib.animation.FuncAnimation at 0x7fb03cdd79b0>"]},"metadata":{"tags":[]},"execution_count":28}]},{"metadata":{"id":"FOqOuK5UdxZ6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}